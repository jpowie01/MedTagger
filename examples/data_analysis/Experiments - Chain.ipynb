{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment // Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "At the beginning, let's import the most important modules and classes from the MedTagger internal API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "from medtagger.database import models\n",
    "from medtagger.ground_truth.algorithms.majority_voting import MajorityVotingAlgorithm\n",
    "from medtagger.ground_truth.algorithms.gaussian_mixture_models import GaussianMixtureModelsAlgorithm\n",
    "from medtagger.ground_truth.algorithms.k_means import KMeansAlgorithm\n",
    "from medtagger.ground_truth.algorithms.dbscan import DBSCANAlgorithm\n",
    "from medtagger.ground_truth.parsers.chain import ChainLabelElementParser\n",
    "from medtagger.ground_truth.generator import DataSetGenerator\n",
    "from medtagger.ground_truth.quality import figures\n",
    "from medtagger.ground_truth.quality.user_specificity_sensitivity import \\\n",
    "    compute_specificity_and_sensitivity_for_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [8.0, 6.0]\n",
    "plt.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCAN_IDS = [\n",
    "    '03647f36-d874-480b-aaec-c2c3b9d80092',\n",
    "    '40761156-99db-4647-9b72-8e449e6cb54c',\n",
    "    'b750320e-5664-4eff-b4c7-49e4f43ce6ca',\n",
    "    '8b5d264d-bc2f-458f-ba68-2a987d55deae',\n",
    "    '7985ea16-d5a4-4bda-92db-43a3cc074216'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Generator instance\n",
    "\n",
    "To create Ground Truth data set, all you need is to define your data set generator and an algorithm that should be used during generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm = MajorityVotingAlgorithm()\n",
    "# algorithm = GaussianMixtureModelsAlgorithm()\n",
    "# algorithm = KMeansAlgorithm()\n",
    "algorithm = DBSCANAlgorithm()\n",
    "generator = DataSetGenerator(algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERCENTILE = 0\n",
    "# PERCENTILE = 50\n",
    "PERCENTILE = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_algorithm = MajorityVotingAlgorithm()\n",
    "mv_generator = DataSetGenerator(algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ChainLabelElementParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Scans for analysis\n",
    "\n",
    "Then, select all Scans that you would like to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan IDs: {'7985ea16-d5a4-4bda-92db-43a3cc074216', 'b750320e-5664-4eff-b4c7-49e4f43ce6ca', '03647f36-d874-480b-aaec-c2c3b9d80092', '8b5d264d-bc2f-458f-ba68-2a987d55deae', '40761156-99db-4647-9b72-8e449e6cb54c'}\n"
     ]
    }
   ],
   "source": [
    "scans = models.Scan.query.all()\n",
    "scans_ids = {scan.id for scan in scans}\n",
    "print(f'Scan IDs: {scans_ids}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Label Elements for analysis\n",
    "\n",
    "Now, select all Label Elements that should be analysed.\n",
    "\n",
    "**IMPORTANT:** Currently Data Set Generator assumes only one Label Element per Slice. Don't worry, this will change in the near future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1103 Chain Label Elements from ETI.\n",
      "There are 422 Chain Label Elements from GUMED.\n",
      "There are 1525 Chain Label Elements from ETI & GUMED.\n",
      "There are 130 Chain Label Elements from EXPERT.\n",
      "Example: <ChainLabelElement: a14fa6c3-d9f4-44e1-a4aa-92d7dac3a3a9: 6 True>\n"
     ]
    }
   ],
   "source": [
    "query = models.ChainLabelElement.query.join(models.Label).join(models.User)\n",
    "query = query.filter(models.Label.scan_id.in_(scans_ids))\n",
    "eti_chain_label_elements = query.filter(models.User.last_name == 'ETI').all()\n",
    "gumed_chain_label_elements = query.filter(models.User.last_name == 'GUMED').all()\n",
    "expert_chain_label_elements = query.filter(models.User.last_name == 'EXPERT').all()\n",
    "combined_chain_label_elements = query.filter(models.User.last_name.in_(['ETI', 'GUMED'])).all()\n",
    "print(f'There are {len(eti_chain_label_elements)} Chain Label Elements from ETI.')\n",
    "print(f'There are {len(gumed_chain_label_elements)} Chain Label Elements from GUMED.')\n",
    "print(f'There are {len(combined_chain_label_elements)} Chain Label Elements from ETI & GUMED.')\n",
    "print(f'There are {len(expert_chain_label_elements)} Chain Label Elements from EXPERT.')\n",
    "print(f'Example: {eti_chain_label_elements[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Ground Truth data set\n",
    "\n",
    "Take your Label Elements and use generator to generate output Ground Truth annotations for each Slice that took part in the labeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ground_truth_expert = mv_generator.generate(expert_chain_label_elements)\n",
    "# ground_truth_expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ground_truth_eti = generator.generate(eti_chain_label_elements)\n",
    "# ground_truth_eti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gumed_chain_label_elements = [s for s in gumed_chain_label_elements\n",
    "                              if s.slice_index < len(s.label.scan.slices)]\n",
    "ground_truth_gumed = generator.generate(gumed_chain_label_elements)\n",
    "# ground_truth_gumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_chain_label_elements = [s for s in combined_chain_label_elements\n",
    "                                 if s.slice_index < len(s.label.scan.slices)]\n",
    "ground_truth_combined = generator.generate(combined_chain_label_elements)\n",
    "# ground_truth_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Table 1] Expert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_per_scan = {}\n",
    "for slice_id in ground_truth_expert:\n",
    "    scan_id = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first().id\n",
    "    if ground_truth_expert[slice_id] is not None:\n",
    "        if labels_per_scan.get(scan_id) is None:\n",
    "            labels_per_scan[scan_id] = 0\n",
    "        labels_per_scan[scan_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_per_scan = {}\n",
    "for scan in models.Scan.query.all():\n",
    "    scan_id = scan.id\n",
    "    slices_per_scan[scan_id] = len(scan.slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03647f36-d874-480b-aaec-c2c3b9d80092 -> 10 labels, 28 slices\n",
      "40761156-99db-4647-9b72-8e449e6cb54c -> 6 labels, 22 slices\n",
      "b750320e-5664-4eff-b4c7-49e4f43ce6ca -> 10 labels, 28 slices\n",
      "8b5d264d-bc2f-458f-ba68-2a987d55deae -> 10 labels, 28 slices\n",
      "7985ea16-d5a4-4bda-92db-43a3cc074216 -> 26 labels, 50 slices\n"
     ]
    }
   ],
   "source": [
    "for scan_id in SCAN_IDS:\n",
    "    print(scan_id, '->', labels_per_scan[scan_id], 'labels,', slices_per_scan[scan_id], 'slices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Table 1] Valid vs. Invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eti_valid_labels = {}\n",
    "# eti_total_labels = {}\n",
    "\n",
    "# for e in eti_chain_label_elements:\n",
    "#     scan_id = e.label.scan.id\n",
    "#     slice_id = e.label.scan.slices[e.slice_index].id\n",
    "#     if eti_valid_labels.get(scan_id) is None:\n",
    "#         eti_valid_labels[scan_id] = 0\n",
    "#         eti_total_labels[scan_id] = 0\n",
    "#     if ground_truth_expert[slice_id] is not None:\n",
    "#         eti_valid_labels[scan_id] += 1\n",
    "#     eti_total_labels[scan_id] += 1\n",
    "\n",
    "# gumed_valid_labels = {}\n",
    "# gumed_total_labels = {}\n",
    "\n",
    "# for e in gumed_chain_label_elements:\n",
    "#     if e.slice_index >= len(e.label.scan.slices):\n",
    "#         continue\n",
    "#     scan_id = e.label.scan.id\n",
    "#     slice_id = e.label.scan.slices[e.slice_index].id\n",
    "#     if gumed_valid_labels.get(scan_id) is None:\n",
    "#         gumed_valid_labels[scan_id] = 0\n",
    "#         gumed_total_labels[scan_id] = 0\n",
    "#     if ground_truth_expert[slice_id] is not None:\n",
    "#         gumed_valid_labels[scan_id] += 1\n",
    "#     gumed_total_labels[scan_id] += 1\n",
    "\n",
    "# for scan_id in SCAN_IDS:\n",
    "#     print(' {:.3f}%'.format(100 * eti_valid_labels[scan_id] / eti_total_labels[scan_id]),\n",
    "#           '\\t{:.3f}%'.format(100 * (eti_total_labels[scan_id] - eti_valid_labels[scan_id]) / eti_total_labels[scan_id]),\n",
    "#           '\\t{:.3f}%'.format(100 * gumed_valid_labels[scan_id] / gumed_total_labels[scan_id]),\n",
    "#           '\\t{:.3f}%'.format(100 * (gumed_total_labels[scan_id] - gumed_valid_labels[scan_id]) / gumed_total_labels[scan_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Table 2] Dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eti_differences = collections.defaultdict(lambda: [])\n",
    "\n",
    "# for e in eti_chain_label_elements:\n",
    "#     scan_id = e.label.scan.id\n",
    "#     slice_id = e.label.scan.slices[e.slice_index].id\n",
    "#     gt_image = ground_truth_expert.get(slice_id)\n",
    "#     if gt_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_image = np.zeros((e.label.scan.width * e.label.scan.height))\n",
    "#     e_image = parser.convert_to_numpy([e], resize_image=algorithm.REQUIRE_IMAGE_RESIZE)\n",
    "#     eti_differences[scan_id].append(np.sum(np.abs(e_image - gt_image)) / gt_image.shape[0])\n",
    "\n",
    "\n",
    "# gumed_differences = collections.defaultdict(lambda: [])\n",
    "\n",
    "# for e in gumed_chain_label_elements:\n",
    "#     scan_id = e.label.scan.id\n",
    "#     slice_id = e.label.scan.slices[e.slice_index].id\n",
    "#     gt_image = ground_truth_expert.get(slice_id)\n",
    "#     if gt_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_image = np.zeros((e.label.scan.width * e.label.scan.height))\n",
    "#     e_image = parser.convert_to_numpy([e], resize_image=algorithm.REQUIRE_IMAGE_RESIZE)\n",
    "#     gumed_differences[scan_id].append(np.sum(np.abs(e_image - gt_image)) / gt_image.shape[0])\n",
    "    \n",
    "# for scan_id in SCAN_IDS:\n",
    "#     print(' {:.3f}%'.format(np.std(eti_differences[scan_id]) * 100),\n",
    "#           '\\t{:.3f}%'.format(np.std(gumed_differences[scan_id]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Table 3] Dispersion in generated Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_eti_differences = collections.defaultdict(lambda: 0)\n",
    "# gt_eti_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "# gt_gumed_differences = collections.defaultdict(lambda: 0)\n",
    "# gt_gumed_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "# for slice_id in ground_truth_eti:\n",
    "#     scan = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first()\n",
    "#     scan_id = scan.id\n",
    "    \n",
    "#     gt_eti_image = ground_truth_eti.get(slice_id)\n",
    "#     if gt_eti_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_eti_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_eti_image = np.zeros((scan.width * scan.height))\n",
    "            \n",
    "#     gt_image = ground_truth_expert.get(slice_id)\n",
    "#     if gt_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_image = np.zeros((scan.width * scan.height))\n",
    "\n",
    "#     gt_eti_differences[scan_id] += np.sum(np.abs(gt_eti_image - gt_image))\n",
    "#     gt_eti_total[scan_id] += gt_image.shape[0]\n",
    "\n",
    "# for slice_id in ground_truth_gumed:\n",
    "#     scan = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first()\n",
    "#     scan_id = scan.id\n",
    "    \n",
    "#     gt_gumed_image = ground_truth_gumed.get(slice_id)\n",
    "#     if gt_gumed_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_gumed_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_gumed_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "#     gt_image = ground_truth_expert.get(slice_id)\n",
    "#     if gt_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_image = np.zeros((scan.width * scan.height))\n",
    "\n",
    "#     gt_gumed_differences[scan_id] += np.sum(np.abs(gt_gumed_image - gt_image))\n",
    "#     gt_gumed_total[scan_id] += gt_image.shape[0]\n",
    "\n",
    "# for scan_id in SCAN_IDS:\n",
    "#     print(' {:.3f}%'.format(gt_eti_differences[scan_id] / gt_eti_total[scan_id] * 100),\n",
    "#           '\\t{:.3f}%'.format(gt_gumed_differences[scan_id] / gt_gumed_total[scan_id] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [GUMED] Check Users' Specificity and Sensitivity\n",
    "\n",
    "MedTagger supports easy calculation of Users' Specificity, Sensitivity and Score based on their annotations and Ground Truth data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 Users.\n"
     ]
    }
   ],
   "source": [
    "gumed_users = set(element.label.owner for element in gumed_chain_label_elements)\n",
    "print(f'There are {len(gumed_users)} Users.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumed_users_specificity, gumed_users_sensitivity, gumed_users_scores = \\\n",
    "    compute_specificity_and_sensitivity_for_users(algorithm, gumed_users,\n",
    "                                                  gumed_chain_label_elements,\n",
    "                                                  ground_truth_gumed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User #103: Sensitivity=0.85938 Specificity=1.00000 Score=0.73853\n",
      "User #104: Sensitivity=0.03125 Specificity=0.98913 Score=0.00042\n",
      "User #106: Sensitivity=0.14062 Specificity=1.00000 Score=0.01978\n",
      "User #107: Sensitivity=0.89062 Specificity=0.97826 Score=0.75496\n",
      "User #109: Sensitivity=0.15625 Specificity=1.00000 Score=0.02441\n",
      "User #116: Sensitivity=0.85938 Specificity=1.00000 Score=0.73853\n",
      "User #117: Sensitivity=0.15625 Specificity=0.98913 Score=0.02114\n",
      "User #118: Sensitivity=0.48438 Specificity=1.00000 Score=0.23462\n",
      "User #119: Sensitivity=0.04688 Specificity=0.98913 Score=0.00130\n",
      "User #120: Sensitivity=0.92188 Specificity=0.98913 Score=0.82993\n",
      "User #121: Sensitivity=0.54688 Specificity=1.00000 Score=0.29907\n",
      "User #123: Sensitivity=0.92188 Specificity=1.00000 Score=0.84985\n"
     ]
    }
   ],
   "source": [
    "users_ids = set(u.id for u in gumed_users)\n",
    "for user_id in users_ids:\n",
    "    print(f'User #{user_id:03d}: Sensitivity={gumed_users_sensitivity[user_id]:1.5f} '\n",
    "          f'Specificity={gumed_users_specificity[user_id]:1.5f} Score={gumed_users_scores[user_id]:1.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figures.specificity_vs_sensitivity(gumed_users_specificity, gumed_users_sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [GUMED] Compare Labeling Time to Users' Score\n",
    "\n",
    "You can also check how User's mean Labeling Time outputs in their achieved scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# figures.mean_labeling_time_vs_score(gumed_chain_label_elements, gumed_users_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ETI] Check Users' Specificity and Sensitivity\n",
    "\n",
    "MedTagger supports easy calculation of Users' Specificity, Sensitivity and Score based on their annotations and Ground Truth data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 35 Users.\n"
     ]
    }
   ],
   "source": [
    "eti_users = set(element.label.owner for element in eti_chain_label_elements)\n",
    "print(f'There are {len(eti_users)} Users.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eti_users_specificity, eti_users_sensitivity, eti_users_scores = \\\n",
    "    compute_specificity_and_sensitivity_for_users(algorithm, eti_users,\n",
    "                                                  eti_chain_label_elements,\n",
    "                                                  ground_truth_eti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User #003: Sensitivity=0.43662 Specificity=1.00000 Score=0.19064\n",
      "User #005: Sensitivity=0.52113 Specificity=1.00000 Score=0.27157\n",
      "User #025: Sensitivity=0.46479 Specificity=1.00000 Score=0.21603\n",
      "User #031: Sensitivity=0.56338 Specificity=0.94118 Score=0.25458\n",
      "User #033: Sensitivity=0.28169 Specificity=1.00000 Score=0.07935\n",
      "User #034: Sensitivity=0.47887 Specificity=1.00000 Score=0.22932\n",
      "User #035: Sensitivity=0.39437 Specificity=1.00000 Score=0.15552\n",
      "User #036: Sensitivity=0.38028 Specificity=1.00000 Score=0.14461\n",
      "User #037: Sensitivity=0.45070 Specificity=1.00000 Score=0.20313\n",
      "User #039: Sensitivity=0.01408 Specificity=1.00000 Score=0.00020\n",
      "User #040: Sensitivity=0.47887 Specificity=1.00000 Score=0.22932\n",
      "User #041: Sensitivity=0.45070 Specificity=0.98824 Score=0.19267\n",
      "User #042: Sensitivity=0.45070 Specificity=1.00000 Score=0.20313\n",
      "User #043: Sensitivity=0.39437 Specificity=1.00000 Score=0.15552\n",
      "User #044: Sensitivity=0.74648 Specificity=0.98824 Score=0.53980\n",
      "User #048: Sensitivity=0.16901 Specificity=0.90588 Score=0.00561\n",
      "User #049: Sensitivity=0.04225 Specificity=0.98824 Score=0.00093\n",
      "User #052: Sensitivity=0.39437 Specificity=1.00000 Score=0.15552\n",
      "User #053: Sensitivity=0.02817 Specificity=1.00000 Score=0.00079\n",
      "User #054: Sensitivity=0.49296 Specificity=1.00000 Score=0.24301\n",
      "User #055: Sensitivity=0.54930 Specificity=0.98824 Score=0.28894\n",
      "User #056: Sensitivity=0.49296 Specificity=1.00000 Score=0.24301\n",
      "User #058: Sensitivity=0.50704 Specificity=1.00000 Score=0.25709\n",
      "User #059: Sensitivity=0.46479 Specificity=1.00000 Score=0.21603\n",
      "User #060: Sensitivity=0.43662 Specificity=1.00000 Score=0.19064\n",
      "User #065: Sensitivity=0.36620 Specificity=1.00000 Score=0.13410\n",
      "User #067: Sensitivity=0.50704 Specificity=0.98824 Score=0.24530\n",
      "User #072: Sensitivity=0.52113 Specificity=1.00000 Score=0.27157\n",
      "User #091: Sensitivity=0.73239 Specificity=1.00000 Score=0.53640\n",
      "User #092: Sensitivity=0.07042 Specificity=1.00000 Score=0.00496\n",
      "User #096: Sensitivity=0.49296 Specificity=1.00000 Score=0.24301\n",
      "User #097: Sensitivity=0.38028 Specificity=1.00000 Score=0.14461\n",
      "User #098: Sensitivity=0.45070 Specificity=1.00000 Score=0.20313\n",
      "User #099: Sensitivity=0.64789 Specificity=0.91765 Score=0.31983\n",
      "User #101: Sensitivity=0.21127 Specificity=1.00000 Score=0.04463\n"
     ]
    }
   ],
   "source": [
    "users_ids = set(u.id for u in eti_users)\n",
    "for user_id in users_ids:\n",
    "    print(f'User #{user_id:03d}: Sensitivity={eti_users_sensitivity[user_id]:1.5f} '\n",
    "          f'Specificity={eti_users_specificity[user_id]:1.5f} Score={eti_users_scores[user_id]:1.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figures.specificity_vs_sensitivity(eti_users_specificity, eti_users_sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ETI] Compare Labeling Time to Users' Score\n",
    "\n",
    "You can also check how User's mean Labeling Time outputs in their achieved scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# figures.mean_labeling_time_vs_score(eti_chain_label_elements, eti_users_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [COMBINED] Check Users' Specificity and Sensitivity\n",
    "\n",
    "MedTagger supports easy calculation of Users' Specificity, Sensitivity and Score based on their annotations and Ground Truth data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 47 Users.\n"
     ]
    }
   ],
   "source": [
    "combined_users = set(element.label.owner for element in combined_chain_label_elements)\n",
    "print(f'There are {len(combined_users)} Users.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_users_specificity, combined_users_sensitivity, combined_users_scores = \\\n",
    "    compute_specificity_and_sensitivity_for_users(algorithm, combined_users,\n",
    "                                                  combined_chain_label_elements,\n",
    "                                                  ground_truth_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User #003: Sensitivity=0.41892 Specificity=1.00000 Score=0.17549\n",
      "User #005: Sensitivity=0.50000 Specificity=1.00000 Score=0.25000\n",
      "User #025: Sensitivity=0.44595 Specificity=1.00000 Score=0.19887\n",
      "User #031: Sensitivity=0.54054 Specificity=0.93902 Score=0.22998\n",
      "User #033: Sensitivity=0.27027 Specificity=1.00000 Score=0.07305\n",
      "User #034: Sensitivity=0.45946 Specificity=1.00000 Score=0.21110\n",
      "User #035: Sensitivity=0.37838 Specificity=1.00000 Score=0.14317\n",
      "User #036: Sensitivity=0.36486 Specificity=1.00000 Score=0.13313\n",
      "User #037: Sensitivity=0.43243 Specificity=1.00000 Score=0.18700\n",
      "User #039: Sensitivity=0.01351 Specificity=1.00000 Score=0.00018\n",
      "User #040: Sensitivity=0.45946 Specificity=1.00000 Score=0.21110\n",
      "User #041: Sensitivity=0.43243 Specificity=0.98780 Score=0.17660\n",
      "User #042: Sensitivity=0.43243 Specificity=1.00000 Score=0.18700\n",
      "User #043: Sensitivity=0.37838 Specificity=1.00000 Score=0.14317\n",
      "User #044: Sensitivity=0.71622 Specificity=0.98780 Score=0.49565\n",
      "User #048: Sensitivity=0.17568 Specificity=0.91463 Score=0.00816\n",
      "User #049: Sensitivity=0.05405 Specificity=1.00000 Score=0.00292\n",
      "User #052: Sensitivity=0.37838 Specificity=1.00000 Score=0.14317\n",
      "User #053: Sensitivity=0.02703 Specificity=1.00000 Score=0.00073\n",
      "User #054: Sensitivity=0.47297 Specificity=1.00000 Score=0.22370\n",
      "User #055: Sensitivity=0.54054 Specificity=1.00000 Score=0.29218\n",
      "User #056: Sensitivity=0.47297 Specificity=1.00000 Score=0.22370\n",
      "User #058: Sensitivity=0.48649 Specificity=1.00000 Score=0.23667\n",
      "User #059: Sensitivity=0.44595 Specificity=1.00000 Score=0.19887\n",
      "User #060: Sensitivity=0.41892 Specificity=1.00000 Score=0.17549\n",
      "User #065: Sensitivity=0.35135 Specificity=1.00000 Score=0.12345\n",
      "User #067: Sensitivity=0.48649 Specificity=0.98780 Score=0.22495\n",
      "User #072: Sensitivity=0.50000 Specificity=1.00000 Score=0.25000\n",
      "User #091: Sensitivity=0.70270 Specificity=1.00000 Score=0.49379\n",
      "User #092: Sensitivity=0.06757 Specificity=1.00000 Score=0.00457\n",
      "User #096: Sensitivity=0.47297 Specificity=1.00000 Score=0.22370\n",
      "User #097: Sensitivity=0.36486 Specificity=1.00000 Score=0.13313\n",
      "User #098: Sensitivity=0.43243 Specificity=1.00000 Score=0.18700\n",
      "User #099: Sensitivity=0.62162 Specificity=0.91463 Score=0.28757\n",
      "User #101: Sensitivity=0.20270 Specificity=1.00000 Score=0.04109\n",
      "User #103: Sensitivity=0.63514 Specificity=1.00000 Score=0.40340\n",
      "User #104: Sensitivity=0.02703 Specificity=1.00000 Score=0.00073\n",
      "User #106: Sensitivity=0.12162 Specificity=1.00000 Score=0.01479\n",
      "User #107: Sensitivity=0.62162 Specificity=0.97561 Score=0.35669\n",
      "User #109: Sensitivity=0.13514 Specificity=1.00000 Score=0.01826\n",
      "User #116: Sensitivity=0.68919 Specificity=1.00000 Score=0.47498\n",
      "User #117: Sensitivity=0.14865 Specificity=1.00000 Score=0.02210\n",
      "User #118: Sensitivity=0.43243 Specificity=1.00000 Score=0.18700\n",
      "User #119: Sensitivity=0.05405 Specificity=1.00000 Score=0.00292\n",
      "User #120: Sensitivity=0.74324 Specificity=1.00000 Score=0.55241\n",
      "User #121: Sensitivity=0.47297 Specificity=1.00000 Score=0.22370\n",
      "User #123: Sensitivity=0.67568 Specificity=1.00000 Score=0.45654\n"
     ]
    }
   ],
   "source": [
    "users_ids = set(u.id for u in combined_users)\n",
    "for user_id in users_ids:\n",
    "    print(f'User #{user_id:03d}: Sensitivity={combined_users_sensitivity[user_id]:1.5f} '\n",
    "          f'Specificity={combined_users_specificity[user_id]:1.5f} Score={combined_users_scores[user_id]:1.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figures.specificity_vs_sensitivity(combined_users_specificity, combined_users_sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [COMBINED] Compare Labeling Time to Users' Score\n",
    "\n",
    "You can also check how User's mean Labeling Time outputs in their achieved scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# figures.mean_labeling_time_vs_score(combined_chain_label_elements, combined_users_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [GUMED] Only best labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[107, 120, 123]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gumed_raw_scores = np.array(list(gumed_users_scores.values()))\n",
    "gumed_median_score = np.percentile(gumed_raw_scores, PERCENTILE)\n",
    "best_gumed_users_id = [u_id for u_id in gumed_users_scores if gumed_users_scores[u_id] >= gumed_median_score]\n",
    "best_gumed_users_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_gumed_chain_label_elements = [e for e in gumed_chain_label_elements\n",
    "                                         if e.label.owner_id in best_gumed_users_id]\n",
    "ground_truth_gumed_best = generator.generate(best_gumed_chain_label_elements)\n",
    "# ground_truth_gumed_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ETI] Only best labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eti_raw_scores = np.array(list(eti_users_scores.values()))\n",
    "eti_median_score = np.percentile(eti_raw_scores, PERCENTILE)\n",
    "best_eti_users_id = [u_id for u_id in eti_users_scores if eti_users_scores[u_id] >= eti_median_score]\n",
    "# best_eti_users_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_eti_chain_label_elements = [e for e in eti_chain_label_elements\n",
    "                                 if e.label.owner_id in best_eti_users_id]\n",
    "ground_truth_eti_best = generator.generate(best_eti_chain_label_elements)\n",
    "# ground_truth_eti_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [COMBINED] Only best labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined_raw_scores = np.array(list(combined_users_scores.values()))\n",
    "combined_median_score = np.percentile(combined_raw_scores, PERCENTILE)\n",
    "best_combined_users_id = [u_id for u_id in combined_users_scores if combined_users_scores[u_id] >= combined_median_score]\n",
    "# best_combined_users_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_combined_chain_label_elements = [e for e in combined_chain_label_elements\n",
    "                                      if e.label.owner_id in best_combined_users_id]\n",
    "ground_truth_combined_best = generator.generate(best_combined_chain_label_elements)\n",
    "# ground_truth_combined_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Table 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gumed_valid_labels = {}\n",
    "# gumed_total_labels = {}\n",
    "\n",
    "# for e in best_gumed_chain_label_elements:\n",
    "#     scan_id = e.label.scan.id\n",
    "#     slice_id = e.label.scan.slices[e.slice_index].id\n",
    "#     if gumed_valid_labels.get(scan_id) is None:\n",
    "#         gumed_valid_labels[scan_id] = 0\n",
    "#         gumed_total_labels[scan_id] = 0\n",
    "#     if ground_truth_expert[slice_id] is not None:\n",
    "#         gumed_valid_labels[scan_id] += 1\n",
    "#     gumed_total_labels[scan_id] += 1\n",
    "\n",
    "# eti_valid_labels = {}\n",
    "# eti_total_labels = {}\n",
    "\n",
    "# for e in best_eti_chain_label_elements:\n",
    "#     scan_id = e.label.scan.id\n",
    "#     slice_id = e.label.scan.slices[e.slice_index].id\n",
    "#     if eti_valid_labels.get(scan_id) is None:\n",
    "#         eti_valid_labels[scan_id] = 0\n",
    "#         eti_total_labels[scan_id] = 0\n",
    "#     if ground_truth_expert[slice_id] is not None:\n",
    "#         eti_valid_labels[scan_id] += 1\n",
    "#     eti_total_labels[scan_id] += 1\n",
    "\n",
    "# for scan_id in SCAN_IDS:\n",
    "#     print(' {:.3f}%'.format(100 * eti_valid_labels[scan_id] / eti_total_labels[scan_id]),\n",
    "#           '\\t{:.3f}%'.format(100 * (eti_total_labels[scan_id] - eti_valid_labels[scan_id]) / eti_total_labels[scan_id]),\n",
    "#           '\\t{:.3f}%'.format(100 * gumed_valid_labels[scan_id] / gumed_total_labels[scan_id]),\n",
    "#           '\\t{:.3f}%'.format(100 * (gumed_total_labels[scan_id] - gumed_valid_labels[scan_id]) / gumed_total_labels[scan_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #\n",
    "# # Dla Dawida\n",
    "# #\n",
    "# user_emails = set()\n",
    "\n",
    "# gumed_differences = collections.defaultdict(lambda: collections.defaultdict(lambda: 0))\n",
    "# gumed_total = collections.defaultdict(lambda: collections.defaultdict(lambda: 0))\n",
    "\n",
    "# for e in best_gumed_chain_label_elements:\n",
    "#     user_id = e.label.owner.email\n",
    "#     user_emails.add(user_id)\n",
    "#     scan = e.label.scan\n",
    "#     scan_id = scan.id\n",
    "#     slice_id = e.label.scan.slices[e.slice_index].id\n",
    "#     gumed_image = parser.convert_to_numpy([e], algorithm.REQUIRE_IMAGE_RESIZE)[0]\n",
    "#     gt_image = ground_truth_expert.get(slice_id)\n",
    "#     if gt_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "#     iou = parser.compute_intersection_over_union(gumed_image, gt_image)\n",
    "#     if not np.isnan(iou):\n",
    "#         gumed_differences[user_id][scan_id] += iou\n",
    "#         gumed_total[user_id][scan_id] += 1\n",
    "\n",
    "# for slice_id in ground_truth_expert:\n",
    "#     for gumed_id in best_gumed_users_id:\n",
    "#         user = models.User.query.filter(models.User.id == gumed_id).first()\n",
    "        \n",
    "#         gumed_label_element = next((e for e in best_gumed_chain_label_elements\n",
    "#                                     if e.label.scan.slices[e.slice_index].id == slice_id\n",
    "#                                       and e.label.owner_id == gumed_id\n",
    "#                                    ), None)\n",
    "        \n",
    "#         if ground_truth_expert.get(slice_id) is not None and gumed_label_element is None:\n",
    "#             scan_id = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first().id\n",
    "#             gumed_differences[user.email][scan_id] += 0\n",
    "#             gumed_total[user.email][scan_id] += 1\n",
    "        \n",
    "# eti_differences = collections.defaultdict(lambda: collections.defaultdict(lambda: 0))\n",
    "# eti_total = collections.defaultdict(lambda: collections.defaultdict(lambda: 0))\n",
    "\n",
    "# for e in best_eti_chain_label_elements:\n",
    "#     user_id = e.label.owner.email\n",
    "#     user_emails.add(user_id)\n",
    "#     scan = e.label.scan\n",
    "#     scan_id = scan.id\n",
    "#     slice_id = e.label.scan.slices[e.slice_index].id\n",
    "#     eti_image = parser.convert_to_numpy([e], algorithm.REQUIRE_IMAGE_RESIZE)[0]\n",
    "#     gt_image = ground_truth_expert.get(slice_id)\n",
    "#     if gt_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "#     iou = parser.compute_intersection_over_union(eti_image, gt_image)\n",
    "#     if not np.isnan(iou):\n",
    "#         eti_differences[user_id][scan_id] += iou\n",
    "#         eti_total[user_id][scan_id] += 1\n",
    "\n",
    "\n",
    "# for slice_id in ground_truth_expert:\n",
    "#     for eti_id in best_eti_users_id:\n",
    "#         user = models.User.query.filter(models.User.id == eti_id).first()\n",
    "        \n",
    "#         eti_label_element = next((e for e in best_eti_chain_label_elements\n",
    "#                                     if e.label.scan.slices[e.slice_index].id == slice_id\n",
    "#                                       and e.label.owner_id == eti_id\n",
    "#                                    ), None)\n",
    "        \n",
    "#         if ground_truth_expert.get(slice_id) is not None and eti_label_element is None:\n",
    "#             scan_id = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first().id\n",
    "#             eti_differences[user.email][scan_id] += 0\n",
    "#             eti_total[user.email][scan_id] += 1\n",
    "        \n",
    "# for user_id in user_emails:\n",
    "#     for scan_id in SCAN_IDS:\n",
    "#         if eti_total[user_id][scan_id] > 0:\n",
    "#             iou = eti_differences[user_id][scan_id] / eti_total[user_id][scan_id] * 100\n",
    "#         elif gumed_total[user_id][scan_id] > 0:\n",
    "#             iou = gumed_differences[user_id][scan_id] / gumed_total[user_id][scan_id] * 100\n",
    "#         else:\n",
    "#             iou = 0\n",
    "#         label = models.Label.query.join(models.User).filter(models.User.email == user_id)\\\n",
    "#                    .filter(models.Label.scan_id == scan_id).first()\n",
    "#         cant_see_anything = False if label is None else label.comment == 'This is an empty Label'\n",
    "#         timestamp = 0 if label is None else label.labeling_time\n",
    "#         print('{}\\t{}\\t{:.3f}%\\t{}\\t{}'.format(user_id, scan_id, iou, timestamp, cant_see_anything))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection over Union - między wprowadzonymi etykietami a prawdziwym Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70.219% \t74.915% \t72.634%\n",
      " 60.979% \t67.968% \t63.090%\n",
      " 63.638% \t55.264% \t62.292%\n",
      " 68.789% \t69.769% \t68.432%\n",
      " 17.434% \t75.397% \t42.857%\n"
     ]
    }
   ],
   "source": [
    "gumed_differences = collections.defaultdict(lambda: 0)\n",
    "gumed_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "for e in best_gumed_chain_label_elements:\n",
    "    scan = e.label.scan\n",
    "    scan_id = scan.id\n",
    "    slice_id = e.label.scan.slices[e.slice_index].id\n",
    "    gumed_image = parser.convert_to_numpy([e], algorithm.REQUIRE_IMAGE_RESIZE)[0]\n",
    "    gt_image = ground_truth_expert.get(slice_id)\n",
    "    if gt_image is None:\n",
    "        if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "            gt_image = np.zeros((100 * 100))\n",
    "        else:\n",
    "            gt_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "    iou = parser.compute_intersection_over_union(gumed_image, gt_image)\n",
    "    if not np.isnan(iou):\n",
    "        gumed_differences[scan_id] += iou\n",
    "        gumed_total[scan_id] += 1\n",
    "\n",
    "for slice_id in ground_truth_expert:\n",
    "    for gumed_id in best_gumed_users_id:\n",
    "        user = models.User.query.filter(models.User.id == gumed_id).first()\n",
    "        \n",
    "        gumed_label_element = next((e for e in best_gumed_chain_label_elements\n",
    "                                    if e.label.scan.slices[e.slice_index].id == slice_id\n",
    "                                      and e.label.owner_id == gumed_id\n",
    "                                   ), None)\n",
    "        \n",
    "        if ground_truth_expert.get(slice_id) is not None and gumed_label_element is None:\n",
    "            scan_id = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first().id\n",
    "            gumed_differences[scan_id] += 0\n",
    "            gumed_total[scan_id] += 1\n",
    "\n",
    "eti_differences = collections.defaultdict(lambda: 0)\n",
    "eti_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "for e in best_eti_chain_label_elements:\n",
    "    scan = e.label.scan\n",
    "    scan_id = scan.id\n",
    "    slice_id = e.label.scan.slices[e.slice_index].id\n",
    "    eti_image = parser.convert_to_numpy([e], algorithm.REQUIRE_IMAGE_RESIZE)[0]\n",
    "    gt_image = ground_truth_expert.get(slice_id)\n",
    "    if gt_image is None:\n",
    "        if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "            gt_image = np.zeros((100 * 100))\n",
    "        else:\n",
    "            gt_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "    iou = parser.compute_intersection_over_union(eti_image, gt_image)\n",
    "    if not np.isnan(iou):\n",
    "        eti_differences[scan_id] += iou\n",
    "        eti_total[scan_id] += 1\n",
    "\n",
    "for slice_id in ground_truth_expert:\n",
    "    for eti_id in best_eti_users_id:\n",
    "        user = models.User.query.filter(models.User.id == eti_id).first()\n",
    "        \n",
    "        eti_label_element = next((e for e in best_eti_chain_label_elements\n",
    "                                    if e.label.scan.slices[e.slice_index].id == slice_id\n",
    "                                      and e.label.owner_id == eti_id\n",
    "                                   ), None)\n",
    "        \n",
    "        if ground_truth_expert.get(slice_id) is not None and eti_label_element is None:\n",
    "            scan_id = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first().id\n",
    "            eti_differences[scan_id] += 0\n",
    "            eti_total[scan_id] += 1\n",
    "\n",
    "combined_differences = collections.defaultdict(lambda: 0)\n",
    "combined_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "for e in best_combined_chain_label_elements:\n",
    "    scan = e.label.scan\n",
    "    scan_id = scan.id\n",
    "    slice_id = e.label.scan.slices[e.slice_index].id\n",
    "    combined_image = parser.convert_to_numpy([e], algorithm.REQUIRE_IMAGE_RESIZE)[0]\n",
    "    gt_image = ground_truth_expert.get(slice_id)\n",
    "    if gt_image is None:\n",
    "        if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "            gt_image = np.zeros((100 * 100))\n",
    "        else:\n",
    "            gt_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "    iou = parser.compute_intersection_over_union(combined_image, gt_image)\n",
    "    if not np.isnan(iou):\n",
    "        combined_differences[scan_id] += iou\n",
    "        combined_total[scan_id] += 1\n",
    "\n",
    "for slice_id in ground_truth_expert:\n",
    "    for eti_id in best_combined_users_id:\n",
    "        user = models.User.query.filter(models.User.id == eti_id).first()\n",
    "        \n",
    "        eti_label_element = next((e for e in best_combined_chain_label_elements\n",
    "                                    if e.label.scan.slices[e.slice_index].id == slice_id\n",
    "                                      and e.label.owner_id == eti_id\n",
    "                                   ), None)\n",
    "        \n",
    "        if ground_truth_expert.get(slice_id) is not None and eti_label_element is None:\n",
    "            scan_id = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first().id\n",
    "            combined_differences[scan_id] += 0\n",
    "            combined_total[scan_id] += 1\n",
    "\n",
    "for scan_id in SCAN_IDS:\n",
    "    print(' {:.3f}%'.format(eti_differences[scan_id] / eti_total[scan_id] * 100),\n",
    "          '\\t{:.3f}%'.format(gumed_differences[scan_id] / gumed_total[scan_id] * 100),\n",
    "          '\\t{:.3f}%'.format(combined_differences[scan_id] / combined_total[scan_id] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection over Union - między wyliczonym Ground Truth a prawdziwym Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TEMPORARY\n",
    "#\n",
    "\n",
    "# gt_eti_differences = collections.defaultdict(lambda: 0)\n",
    "# gt_eti_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "# for slice_id in ground_truth_eti_best:\n",
    "#     scan = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first()\n",
    "#     scan_id = scan.id\n",
    "    \n",
    "#     gt_eti_image = ground_truth_eti_best.get(slice_id)\n",
    "#     if gt_eti_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_eti_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_eti_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "#     gt_image = ground_truth_expert.get(slice_id)\n",
    "#     if gt_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_image = np.zeros((scan.width * scan.height))\n",
    "\n",
    "#     iou = parser.compute_intersection_over_union(gt_eti_image, gt_image)\n",
    "#     if not np.isnan(iou):\n",
    "#         gt_eti_differences[scan_id] += iou\n",
    "#         gt_eti_total[scan_id] += 1\n",
    "\n",
    "# gt_gumed_differences = collections.defaultdict(lambda: 0)\n",
    "# gt_gumed_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "# for slice_id in ground_truth_gumed_best:\n",
    "#     scan = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first()\n",
    "#     scan_id = scan.id\n",
    "    \n",
    "#     gt_gumed_image = ground_truth_gumed_best.get(slice_id)\n",
    "#     if gt_gumed_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_gumed_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_gumed_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "#     gt_image = ground_truth_expert.get(slice_id)\n",
    "#     if gt_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "#     iou = parser.compute_intersection_over_union(gt_gumed_image, gt_image)\n",
    "#     if not np.isnan(iou):\n",
    "#         gt_gumed_differences[scan_id] += iou\n",
    "#         gt_gumed_total[scan_id] += 1\n",
    "\n",
    "# gt_combined_differences = collections.defaultdict(lambda: 0)\n",
    "# gt_combined_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "# for slice_id in ground_truth_combined_best:\n",
    "#     scan = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first()\n",
    "#     scan_id = scan.id\n",
    "    \n",
    "#     gt_combined_image = ground_truth_combined_best.get(slice_id)\n",
    "#     if gt_combined_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_combined_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_combined_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "#     gt_image = ground_truth_expert.get(slice_id)\n",
    "#     if gt_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "#     iou = parser.compute_intersection_over_union(gt_combined_image, gt_image)\n",
    "#     if not np.isnan(iou):\n",
    "#         gt_combined_differences[scan_id] += iou\n",
    "#         gt_combined_total[scan_id] += 1\n",
    "\n",
    "# for scan_id in SCAN_IDS:\n",
    "#     print(' {:.3f}%'.format(gt_eti_differences[scan_id] / gt_eti_total[scan_id] * 100),\n",
    "#           '\\t{:.3f}%'.format(gt_gumed_differences[scan_id] / gt_gumed_total[scan_id] * 100),\n",
    "#           '\\t{:.3f}%'.format(gt_combined_differences[scan_id] / gt_combined_total[scan_id] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Average Precision @ 0.75 - między wprowadzonymi etykietami a prawdziwym Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66.337% \t81.818% \t71.212%\n",
      " 66.154% \t71.429% \t67.857%\n",
      " 48.421% \t36.667% \t45.082%\n",
      " 60.870% \t61.290% \t59.504%\n",
      " 14.516% \t72.500% \t38.700%\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.75\n",
    "\n",
    "gumed_differences = collections.defaultdict(lambda: 0)\n",
    "gumed_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "for e in best_gumed_chain_label_elements:\n",
    "    scan = e.label.scan\n",
    "    scan_id = scan.id\n",
    "    slice_id = e.label.scan.slices[e.slice_index].id\n",
    "    gumed_image = parser.convert_to_numpy([e], algorithm.REQUIRE_IMAGE_RESIZE)[0]\n",
    "    gt_image = ground_truth_expert.get(slice_id)\n",
    "    if gt_image is None:\n",
    "        if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "            gt_image = np.zeros((100 * 100))\n",
    "        else:\n",
    "            gt_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "    iou = parser.compute_intersection_over_union(gt_image, gumed_image)\n",
    "    iou = 1.0 if np.isnan(iou) else iou\n",
    "    gumed_differences[scan_id] += 1 if iou >= THRESHOLD else 0\n",
    "    gumed_total[scan_id] += 1\n",
    "\n",
    "for slice_id in ground_truth_expert:\n",
    "    for gumed_id in best_gumed_users_id:\n",
    "        user = models.User.query.filter(models.User.id == gumed_id).first()\n",
    "        \n",
    "        gumed_label_element = next((e for e in best_gumed_chain_label_elements\n",
    "                                    if e.label.scan.slices[e.slice_index].id == slice_id\n",
    "                                      and e.label.owner_id == gumed_id\n",
    "                                   ), None)\n",
    "        \n",
    "        if ground_truth_expert.get(slice_id) is not None and gumed_label_element is None:\n",
    "            scan_id = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first().id\n",
    "            gumed_differences[scan_id] += 0\n",
    "            gumed_total[scan_id] += 1\n",
    "\n",
    "eti_differences = collections.defaultdict(lambda: 0)\n",
    "eti_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "for e in best_eti_chain_label_elements:\n",
    "    scan = e.label.scan\n",
    "    scan_id = scan.id\n",
    "    slice_id = e.label.scan.slices[e.slice_index].id\n",
    "    eti_image = parser.convert_to_numpy([e], algorithm.REQUIRE_IMAGE_RESIZE)[0]\n",
    "    gt_image = ground_truth_expert.get(slice_id)\n",
    "    if gt_image is None:\n",
    "        if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "            gt_image = np.zeros((100 * 100))\n",
    "        else:\n",
    "            gt_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "    iou = parser.compute_intersection_over_union(gt_image, eti_image)\n",
    "    iou = 1.0 if np.isnan(iou) else iou\n",
    "    eti_differences[scan_id] += 1 if iou >= THRESHOLD else 0\n",
    "    eti_total[scan_id] += 1\n",
    "\n",
    "for slice_id in ground_truth_expert:\n",
    "    for eti_id in best_eti_users_id:\n",
    "        user = models.User.query.filter(models.User.id == eti_id).first()\n",
    "        \n",
    "        eti_label_element = next((e for e in best_eti_chain_label_elements\n",
    "                                    if e.label.scan.slices[e.slice_index].id == slice_id\n",
    "                                      and e.label.owner_id == eti_id\n",
    "                                   ), None)\n",
    "        \n",
    "        if ground_truth_expert.get(slice_id) is not None and eti_label_element is None:\n",
    "            scan_id = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first().id\n",
    "            eti_differences[scan_id] += 0\n",
    "            eti_total[scan_id] += 1\n",
    "\n",
    "combined_differences = collections.defaultdict(lambda: 0)\n",
    "combined_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "for e in best_combined_chain_label_elements:\n",
    "    scan = e.label.scan\n",
    "    scan_id = scan.id\n",
    "    slice_id = e.label.scan.slices[e.slice_index].id\n",
    "    combined_image = parser.convert_to_numpy([e], algorithm.REQUIRE_IMAGE_RESIZE)[0]\n",
    "    gt_image = ground_truth_expert.get(slice_id)\n",
    "    if gt_image is None:\n",
    "        if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "            gt_image = np.zeros((100 * 100))\n",
    "        else:\n",
    "            gt_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "    iou = parser.compute_intersection_over_union(gt_image, combined_image)\n",
    "    iou = 1.0 if np.isnan(iou) else iou\n",
    "    combined_differences[scan_id] += 1 if iou >= THRESHOLD else 0\n",
    "    combined_total[scan_id] += 1\n",
    "\n",
    "for slice_id in ground_truth_expert:\n",
    "    for eti_id in best_combined_users_id:\n",
    "        user = models.User.query.filter(models.User.id == eti_id).first()\n",
    "        \n",
    "        eti_label_element = next((e for e in best_combined_chain_label_elements\n",
    "                                    if e.label.scan.slices[e.slice_index].id == slice_id\n",
    "                                      and e.label.owner_id == eti_id\n",
    "                                   ), None)\n",
    "        \n",
    "        if ground_truth_expert.get(slice_id) is not None and eti_label_element is None:\n",
    "            scan_id = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first().id\n",
    "            combined_differences[scan_id] += 0\n",
    "            combined_total[scan_id] += 1\n",
    "\n",
    "for scan_id in SCAN_IDS:\n",
    "    print(' {:.3f}%'.format(eti_differences[scan_id] / eti_total[scan_id] * 100),\n",
    "          '\\t{:.3f}%'.format(gumed_differences[scan_id] / gumed_total[scan_id] * 100),\n",
    "          '\\t{:.3f}%'.format(combined_differences[scan_id] / combined_total[scan_id] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Average Precision @ 0.75 - między wyliczonym Ground Truth a prawdziwym Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TEMPORARY\n",
    "#\n",
    "\n",
    "# THRESHOLD = 0.75\n",
    "\n",
    "# gt_eti_differences = collections.defaultdict(lambda: 0)\n",
    "# gt_eti_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "# for slice_id in ground_truth_eti_best:\n",
    "#     scan = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first()\n",
    "#     scan_id = scan.id\n",
    "    \n",
    "#     gt_eti_image = ground_truth_eti_best.get(slice_id)\n",
    "#     if gt_eti_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_eti_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_eti_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "#     gt_image = ground_truth_expert.get(slice_id)\n",
    "#     if gt_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "#     iou = parser.compute_intersection_over_union(gt_eti_image, gt_image)\n",
    "#     iou = 1.0 if np.isnan(iou) else iou\n",
    "#     gt_eti_differences[scan_id] += 1 if iou >= THRESHOLD else 0\n",
    "#     gt_eti_total[scan_id] += 1\n",
    "\n",
    "# gt_gumed_differences = collections.defaultdict(lambda: 0)\n",
    "# gt_gumed_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "# for slice_id in ground_truth_gumed_best:\n",
    "#     scan = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first()\n",
    "#     scan_id = scan.id\n",
    "\n",
    "#     gt_gumed_image = ground_truth_gumed_best.get(slice_id)\n",
    "#     if gt_gumed_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_gumed_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_gumed_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "#     gt_image = ground_truth_expert.get(slice_id)\n",
    "#     if gt_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_image = np.zeros((scan.width * scan.height))\n",
    "\n",
    "#     iou = parser.compute_intersection_over_union(gt_gumed_image, gt_image)\n",
    "#     iou = 1.0 if np.isnan(iou) else iou\n",
    "#     gt_gumed_differences[scan_id] += 1 if iou >= THRESHOLD else 0\n",
    "#     gt_gumed_total[scan_id] += 1\n",
    "\n",
    "# gt_combined_differences = collections.defaultdict(lambda: 0)\n",
    "# gt_combined_total = collections.defaultdict(lambda: 0)\n",
    "\n",
    "# for slice_id in ground_truth_combined_best:\n",
    "#     scan = models.Scan.query.join(models.Slice).filter(models.Slice.id == slice_id).first()\n",
    "#     scan_id = scan.id\n",
    "\n",
    "#     gt_combined_image = ground_truth_combined_best.get(slice_id)\n",
    "#     if gt_combined_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_combined_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_combined_image = np.zeros((scan.width * scan.height))\n",
    "    \n",
    "#     gt_image = ground_truth_expert.get(slice_id)\n",
    "#     if gt_image is None:\n",
    "#         if algorithm.REQUIRE_IMAGE_RESIZE:\n",
    "#             gt_image = np.zeros((100 * 100))\n",
    "#         else:\n",
    "#             gt_image = np.zeros((scan.width * scan.height))\n",
    "\n",
    "#     iou = parser.compute_intersection_over_union(gt_combined_image, gt_image)\n",
    "#     iou = 1.0 if np.isnan(iou) else iou\n",
    "#     gt_combined_differences[scan_id] += 1 if iou >= THRESHOLD else 0\n",
    "#     gt_combined_total[scan_id] += 1\n",
    "\n",
    "# for scan_id in SCAN_IDS:\n",
    "#     print(' {:.3f}%'.format(gt_eti_differences[scan_id] / gt_eti_total[scan_id] * 100),\n",
    "#           '\\t{:.3f}%'.format(gt_gumed_differences[scan_id] / gt_gumed_total[scan_id] * 100),\n",
    "#           '\\t{:.3f}%'.format(gt_combined_differences[scan_id] / gt_combined_total[scan_id] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
